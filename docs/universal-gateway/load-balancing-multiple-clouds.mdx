---
title: Load Balancing Between Multiple Clouds
description: Learn how to load balance traffic between multiple clouds with ngrok.
---

import { LangSwitcher } from "/src/components/LangSwitcher";

ngrok's [Endpoint Pooling](/docs/universal-gateway/endpoint-pooling) allows you to automatically load balance between replicas of your service across multiple clouds by creating two endpoints with the same URL.

This guide will show you how to set up endpoint pooling with a few different methods.

## Why use Endpoint Pooling?

ngrok's Endpoint Pooling:

- Works with the [agent CLI](/docs/agent),
  [SDKs](/docs/agent-sdks/) and our [Kubernetes Operator](/docs/k8s). You can even use all these tools in a single pool.
- Lets you migrate from one deployment strategy to another without hard cut-overs, like moving from using the agent for ingress to embedding ngrok directly in your app/API with an SDK.
- Works with [Traffic Policy](/docs/traffic-policy), enabling you to manage traffic identically across all your replicas from a single "front door", or enforce different policies for each replica.

## Using the CLI

Start with a single [agent endpoint](/docs//docs/universal-gateway/agent-endpoints/) on an ngrok URL, or a [reserved domain](https://dashboard.ngrok.com/domains), with the `--pooling-enabled` flag on.

```bash mode="cli"
ngrok http 8000 --url $YOUR_DOMAIN --pooling-enabled true
```

Repeat the same steps on another cloud where you've deployed a replica of your service. This will start a second internal agent endpoint on the same URL.

```bash mode="cli"
ngrok http 8000 --url $YOUR_DOMAIN --pooling-enabled true
```

### Test your pool

Send a few requests to your domain to see responses balanced between those two endpoints, even though they're running in multiple clouds.

You can verify pooling works in a few ways:

1. Check each agent's UI in the terminal that launched the process. You should see an increase in the number of recent requests.
2. In [Traffic Inspector](https://dashboard.ngrok.com/traffic-inspector), select a request, then select the **Response** tab.
Under **Ngrok-Agent-Ips** you should see that the IP for the responding agent changes from request to request with a similar frequency.

## Using SDKs and other tools

Pooling isn't limited to how you start a given service or its replicas. If you've already started up one agent endpoint with the CLI, you can start up another with one of our [SDKs](/docs/agent-sdks) or the [Kubernetes Operator](/docs/k8s) to load-balance between them.

The following is a simple example of enabling pooling with one of our SDKs.

<LangSwitcher>
```go title="example.go"
package main

import (
	"context"
	"fmt"
	"log"
	"os"

	"github.com/joho/godotenv"
	"golang.ngrok.com/ngrok/v2"
)

func main() {
	if err := godotenv.Load(".env"); err != nil {
		log.Fatal("Error loading .env file", err)
	}
	if err := run(context.Background()); err != nil {
		log.Fatal(err)
	}
}
const address = "http://localhost:8000"

func run(ctx context.Context) error {
	agent, err := ngrok.NewAgent(ngrok.WithAuthtoken(os.Getenv("NGROK_AUTHTOKEN")))
	if err != nil {
	    return err
	}

	ln, err := agent.Forward(ctx,
		ngrok.WithUpstream(address),
		ngrok.WithURL("your-reserved-domain"),
		ngrok.WithPoolingEnabled(true),
	)

	if err != nil {
		fmt.Println("Error", err)
		return err
	}

	fmt.Println("Endpoint online: forwarding from", ln.URL(), "to", address)

	// Explicitly stop forwarding; otherwise it runs indefinitely
	<-ln.Done()
	return nil
}
```

```javascript title="example.js"
require('dotenv').config();
const ngrok = require('@ngrok/ngrok');

(async function() {
    const listener = await ngrok.forward({
        // The port your app is running on.
        addr: 8000,
				domain: "your-reserved-domain",
        authtoken: process.env.NGROK_AUTHTOKEN,
				pooling_enabled: true,
    });

    // Output ngrok url to console
    console.log(`Ingress established at ${listener.url()}`);
})();

// Keep the process alive
process.stdin.resume();
```

```rust title="src/main.rs"
#![deny(warnings)]
use ngrok::config::ForwarderBuilder;
use url::Url;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // Set up ngrok tunnel
    let session = ngrok::Session::builder()
        .authtoken_from_env()
        .connect()
        .await?;

    // Forward HTTP traffic from ngrok to the local server
    let _listener = session
        .http_endpoint()
				.domain("your-reserved-domain")
				.pooling_enabled(true)
        .listen_and_forward(Url::parse("http://localhost:8000").unwrap())
        .await?;

    println!("Ngrok tunnel established at {}", domain);

    // Wait indefinitely
    tokio::signal::ctrl_c().await?;
    Ok(())
}
```

```python title="example.py"
from dotenv import load_dotenv
import os
import ngrok
import time

load_dotenv()

listener = ngrok.forward(
	# The port your app is running on.
  8000,
  authtoken=os.getenv("NGROK_AUTHTOKEN"),
	domain="your-reserved-domain",
	pooling_enabled=True,
)

# Output ngrok url to console
print(f"Ingress established at {listener.url()}")

# Keep the listener alive
try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    print("Closing listener")
```

</LangSwitcher>

If you already have a pool of endpoints created by agent CLIs, make a few requests to see responses from your app using an SDK.

## Using Endpoint Pooling with Cloud Endpoints for custom traffic management

Pooling also works with [internal](/docs/universal-gateway/internal-endpoints/)
Agent Endpoints, which can only receive traffic from the [`forward-internal`
Traffic Policy action](/docs/traffic-policy/actions/forward-internal/) attached
to another endpoint created by your ngrok account.

When you pair a pool of internal agent endpoints with a [Cloud
Endpoint](/docs/universal-gateway/cloud-endpoints/), you have a single "front
door" for your multicloud load-balanced services. That also lets you add traffic
management fundamentals, like authentication, URL rewrites/redirects, or header
manipulation, across all your replicas from one place.

If you want to create your cloud endpoint on the same URL
(`$YOUR_DOMAIN.ngrok.app`), then you'll need to first stop any agents you've
already created on that URL in the first two steps and recreate them on an
internal URL, which ends with `.internal`, like `https://pooling.internal`.

Then jump over to the [**Endpoint**
section](https://dashboard.ngrok.com/endpoints) of your ngrok dashboard. Click
**New**, then **Cloud Endpoint**. Leave the binding as **Public**, enter
`$YOUR_DOMAIN.ngrok.app` for the domain, and click **Create Cloud Endpoint**.

You then need to apply a Traffic Policy and the `forward-internal` actionâ€”the
policy below does one important thing: Route all requests to your pool of
internal agent endpoints.

```yaml
on_http_request:
  - actions:
      - type: forward-internal
        config:
          url: https://pooling.internal
```

Paste the above YAML into the dashboard and click **Save**.

Now when you request `https://$YOUR_DOMAIN.ngrok.app`, your traffic is first
routed through the cloud endpoint before being shared among your pooled internal
agent endpoints.

:::info Coming soon!

Custom load balancing strategies are not yet generally available, but you can
request early access to the developer preview in your [ngrok
dashboard](https://dashboard.ngrok.com/developer-preview).

With custom load balancing strategies, you'll be able to decide exactly what
happens to load-balanced traffic in certain scenarios, like:

- Balance randomly among endpoints in a single cloud provider, then fall back to
  a secondary cloud if they all become unavailable.
- Prioritize endpoints with the most memory regardless of which cloud they were
  deployed from.
- Route traffic to specific cloud providers depending on where the request
  originated from.

:::

## What's next?

If you opted for a Cloud Endpoint that routes traffic to a pool of internal
Agent Endpoints, you can now filter, manage, and orchestrate traffic from that
single endpoint using Traffic Policy. Here's a few of our most popular actions:

- [`oauth`](/docs/traffic-policy/actions/oauth)
- [`url-redirect`](/docs/traffic-policy/actions/url-redirect)
- [`set-vars`](/docs/traffic-policy/actions/set-vars)
- [`add-headers`](/docs/traffic-policy/actions/add-headers)

We didn't cover Kubernetes deployments in this guide, but we have a similar
quickstart guide for [load-balancing K8s
services](/docs/guides/other-guides/load-balancing-kubernetes.mdx). If you're
interested in a more production-ready deployment, take a look at our [multicloud
API gateway setup tutorial](/docs/guides/api-gateway/multicloud).
