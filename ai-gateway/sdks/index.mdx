---
title: SDK Integration
sidebarTitle: Overview
description: Connect your SDK to the ngrok AI Gateway.
---

<Note>
**Prerequisite**: You need an AI Gateway endpoint before using these SDK guides. Create one using the [dashboard quickstart](/ai-gateway/quickstart) or follow the [manual setup guide](/ai-gateway/guides/creating-endpoints).
</Note>

The AI Gateway works with official and third-party SDKs. Simply change the base URL configuration option for your SDK and you're connected.

## Supported SDKs

<CardGroup cols={2}>
  <Card title="OpenAI SDK" icon="circle-nodes" href="/ai-gateway/sdks/openai">
    Official SDKs for Python, TypeScript, Go, Java, and .NET
  </Card>
  <Card title="Anthropic SDK" icon="message-bot" href="/ai-gateway/sdks/anthropic">
    Official SDKs for Python, TypeScript, Java, Go, Ruby, C#, and PHP
  </Card>
  <Card title="Vercel AI SDK" icon="triangle" href="/ai-gateway/sdks/vercel-ai-sdk">
    Build AI apps with React, Next.js, and streaming
  </Card>
  <Card title="TanStack AI" icon="layer-group" href="/ai-gateway/sdks/tanstack-ai">
    Type-safe AI library for React and Solid
  </Card>
  <Card title="LangChain" icon="link" href="/ai-gateway/sdks/langchain">
    Framework for chains, agents, and RAG
  </Card>
  <Card title="Other SDKs" icon="code" href="/ai-gateway/sdks/other">
    cURL, HTTP clients
  </Card>
</CardGroup>

## Quick start

The pattern is the same for any SDK—just change the base URL:

<CodeGroup>
```python Python (OpenAI)
from openai import OpenAI

client = OpenAI(
    base_url="https://your-ai-gateway.ngrok.app/v1",
    api_key="your-api-key"
)
```

```python Python (Anthropic)
import anthropic

client = anthropic.Anthropic(
    base_url="https://your-ai-gateway.ngrok.app",
    api_key="your-api-key"
)
```

```typescript TypeScript (OpenAI)
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "https://your-ai-gateway.ngrok.app/v1",
  apiKey: "your-api-key",
});
```

```typescript TypeScript (Anthropic)
import Anthropic from "@anthropic-ai/sdk";

const client = new Anthropic({
  baseURL: "https://your-ai-gateway.ngrok.app",
  apiKey: "your-api-key",
});
```

```typescript TypeScript (Vercel AI SDK)
import { createOpenAI } from "@ai-sdk/openai";

const openai = createOpenAI({
  baseURL: "https://your-ai-gateway.ngrok.app/v1",
  apiKey: "your-api-key",
});
```

```typescript TypeScript (TanStack AI)
import { openai } from "@tanstack/ai-openai";

const adapter = openai({
  baseURL: "https://your-ai-gateway.ngrok.app/v1",
  apiKey: "your-api-key",
});
```

```python Python (LangChain)
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://your-ai-gateway.ngrok.app/v1",
    api_key="your-api-key",
)
```
</CodeGroup>

## What works through the gateway

Everything your SDK supports works through the gateway:

| Feature | Supported |
|---------|-----------|
| Chat Completions API | ✅ |
| Messages API | ✅ (for Anthropic SDKs)|
| Responses API | ✅ |
| Streaming | ✅ |
| Function/tool calling | ✅ |
| Embeddings | ✅ |
| Async clients | ✅ |
| Retries | ✅ (enhanced by gateway) |

## Gateway benefits

When you route SDK requests through the AI Gateway:

- **Automatic failover** - If one provider fails, the gateway tries another
- **Key rotation** - Use multiple provider API keys to avoid rate limits
- **Provider switching** - Change providers without changing code
- **Observability** - Track usage, latency, and errors across all requests

## Using different providers

Use model prefixes to route to specific providers:

<CodeGroup>
```python OpenAI SDK
# OpenAI
client.chat.completions.create(model="openai:gpt-4o", ...)

# Anthropic
client.chat.completions.create(model="anthropic:claude-3-5-sonnet-latest", ...)

# Your self-hosted Ollama
client.chat.completions.create(model="ollama:llama3.2", ...)
```

```python Anthropic SDK
message = client.messages.create(
    model="anthropic:claude-3-5-sonnet-latest",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
)
```
</CodeGroup>

Or let the gateway choose with `ngrok/auto`:

```python
client.chat.completions.create(model="ngrok/auto", ...)
```

## Next steps

Choose your SDK guide to get started:

- [OpenAI SDK](/ai-gateway/sdks/openai) - Python, TypeScript, Go, Java, .NET
- [Vercel AI SDK](/ai-gateway/sdks/vercel-ai-sdk) - Next.js, React, streaming
- [TanStack AI](/ai-gateway/sdks/tanstack-ai) - Type-safe AI for React, Solid
- [LangChain](/ai-gateway/sdks/langchain) - Chains, agents, RAG
- [Other SDKs](/ai-gateway/sdks/other) - cURL, HTTP clients

